[
  {
    "experiment_id": "Qwen2.5-0.5B_lr1e-05",
    "model": "Qwen/Qwen2.5-0.5B",
    "learning_rate": 1e-05,
    "training_losses": [
      {
        "step": 50,
        "loss": 1.2997196960449218
      },
      {
        "step": 100,
        "loss": 1.2308857727050782
      },
      {
        "step": 150,
        "loss": 1.2382769775390625
      },
      {
        "step": 200,
        "loss": 1.2597550201416015
      },
      {
        "step": 250,
        "loss": 1.2265096282958985
      },
      {
        "step": 300,
        "loss": 1.2153562164306642
      },
      {
        "step": 350,
        "loss": 1.183320541381836
      },
      {
        "step": 400,
        "loss": 1.1770978546142579
      },
      {
        "step": 450,
        "loss": 1.2349313354492188
      },
      {
        "step": 500,
        "loss": 1.2695491790771485
      },
      {
        "step": 550,
        "loss": 1.2705251312255859
      },
      {
        "step": 600,
        "loss": 1.2017300415039063
      },
      {
        "step": 650,
        "loss": 1.2280751800537109
      },
      {
        "step": 700,
        "loss": 1.1663314819335937
      },
      {
        "step": 750,
        "loss": 1.233241653442383
      },
      {
        "step": 800,
        "loss": 1.148424835205078
      },
      {
        "step": 850,
        "loss": 1.2275452423095703
      },
      {
        "step": 900,
        "loss": 1.2225956726074219
      },
      {
        "step": 950,
        "loss": 1.1530883026123047
      },
      {
        "step": 1000,
        "loss": 1.1637399291992188
      },
      {
        "step": 1050,
        "loss": 1.2282974243164062
      },
      {
        "step": 1100,
        "loss": 1.203787612915039
      },
      {
        "step": 1150,
        "loss": 1.1582361602783202
      },
      {
        "step": 1200,
        "loss": 1.1630440521240235
      },
      {
        "step": 1250,
        "loss": 1.197190399169922
      },
      {
        "step": 1300,
        "loss": 1.1240504455566407
      },
      {
        "step": 1350,
        "loss": 1.172742156982422
      },
      {
        "step": 1400,
        "loss": 1.2001571655273438
      },
      {
        "step": 1450,
        "loss": 1.2131722259521485
      },
      {
        "step": 1500,
        "loss": 1.1609237670898438
      },
      {
        "step": 1550,
        "loss": 1.2077090454101562
      },
      {
        "step": 1600,
        "loss": 1.2029528045654296
      },
      {
        "step": 1650,
        "loss": 1.150476608276367
      },
      {
        "step": 1700,
        "loss": 1.1899224090576173
      },
      {
        "step": 1750,
        "loss": 1.1773919677734375
      },
      {
        "step": 1800,
        "loss": 1.1652215576171876
      },
      {
        "step": 1850,
        "loss": 1.1524243927001954
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.158,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.086,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.112,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.09,
            "total": 500
          },
          "language": {
            "accuracy": 0.254,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.156,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.036,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.112,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.256,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.152,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.052,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.112,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.252,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.182,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.082,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.108,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.096,
            "total": 500
          },
          "language": {
            "accuracy": 0.256,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.18,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.09,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.11,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.098,
            "total": 500
          },
          "language": {
            "accuracy": 0.252,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.184,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.07,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.112,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.254,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.186,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.076,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.11,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.088,
            "total": 500
          },
          "language": {
            "accuracy": 0.252,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-0.5B_lr5e-05",
    "model": "Qwen/Qwen2.5-0.5B",
    "learning_rate": 5e-05,
    "training_losses": [
      {
        "step": 50,
        "loss": 1.2525641632080078
      },
      {
        "step": 100,
        "loss": 1.2795127868652343
      },
      {
        "step": 150,
        "loss": 1.3251478576660156
      },
      {
        "step": 200,
        "loss": 1.3490966796875
      },
      {
        "step": 250,
        "loss": 1.3227644348144532
      },
      {
        "step": 300,
        "loss": 1.3125181579589844
      },
      {
        "step": 350,
        "loss": 1.2765665435791016
      },
      {
        "step": 400,
        "loss": 1.269373321533203
      },
      {
        "step": 450,
        "loss": 1.3317037963867187
      },
      {
        "step": 500,
        "loss": 1.3594465637207032
      },
      {
        "step": 550,
        "loss": 1.3560691833496095
      },
      {
        "step": 600,
        "loss": 1.285952606201172
      },
      {
        "step": 650,
        "loss": 1.165216064453125
      },
      {
        "step": 700,
        "loss": 0.9394058227539063
      },
      {
        "step": 750,
        "loss": 1.005680160522461
      },
      {
        "step": 800,
        "loss": 0.930732192993164
      },
      {
        "step": 850,
        "loss": 1.0105581665039063
      },
      {
        "step": 900,
        "loss": 0.9925087738037109
      },
      {
        "step": 950,
        "loss": 0.9276582336425782
      },
      {
        "step": 1000,
        "loss": 0.9322394561767579
      },
      {
        "step": 1050,
        "loss": 0.9934022521972656
      },
      {
        "step": 1100,
        "loss": 0.9841787719726562
      },
      {
        "step": 1150,
        "loss": 0.9305559539794922
      },
      {
        "step": 1200,
        "loss": 0.9416889190673828
      },
      {
        "step": 1250,
        "loss": 0.9667536926269531
      },
      {
        "step": 1300,
        "loss": 0.7578157043457031
      },
      {
        "step": 1350,
        "loss": 0.7937187957763672
      },
      {
        "step": 1400,
        "loss": 0.8072804260253906
      },
      {
        "step": 1450,
        "loss": 0.8198262023925781
      },
      {
        "step": 1500,
        "loss": 0.7856581115722656
      },
      {
        "step": 1550,
        "loss": 0.8198357391357421
      },
      {
        "step": 1600,
        "loss": 0.8111646270751953
      },
      {
        "step": 1650,
        "loss": 0.7717108154296874
      },
      {
        "step": 1700,
        "loss": 0.803803939819336
      },
      {
        "step": 1750,
        "loss": 0.78530517578125
      },
      {
        "step": 1800,
        "loss": 0.7769549560546875
      },
      {
        "step": 1850,
        "loss": 0.7798099517822266
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.158,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.086,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.112,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.09,
            "total": 500
          },
          "language": {
            "accuracy": 0.254,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.192,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.072,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.108,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.096,
            "total": 500
          },
          "language": {
            "accuracy": 0.254,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.172,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.022,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.11,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.09,
            "total": 500
          },
          "language": {
            "accuracy": 0.244,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.164,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.028,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.11,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.094,
            "total": 500
          },
          "language": {
            "accuracy": 0.252,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.164,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.03,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.106,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.094,
            "total": 500
          },
          "language": {
            "accuracy": 0.258,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.148,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.032,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.108,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.244,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.152,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.046,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.106,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.246,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-0.5B_lr0.0001",
    "model": "Qwen/Qwen2.5-0.5B",
    "learning_rate": 0.0001,
    "training_losses": [
      {
        "step": 50,
        "loss": 1.2641048431396484
      },
      {
        "step": 100,
        "loss": 1.4741806030273437
      },
      {
        "step": 150,
        "loss": 1.580328369140625
      },
      {
        "step": 200,
        "loss": 1.608233184814453
      },
      {
        "step": 250,
        "loss": 1.5962202453613281
      },
      {
        "step": 300,
        "loss": 1.583358917236328
      },
      {
        "step": 350,
        "loss": 1.5500526428222656
      },
      {
        "step": 400,
        "loss": 1.5426705932617188
      },
      {
        "step": 450,
        "loss": 1.598965606689453
      },
      {
        "step": 500,
        "loss": 1.6182255554199219
      },
      {
        "step": 550,
        "loss": 1.6098977661132812
      },
      {
        "step": 600,
        "loss": 1.5277932739257813
      },
      {
        "step": 650,
        "loss": 1.2842083740234376
      },
      {
        "step": 700,
        "loss": 0.9315271759033203
      },
      {
        "step": 750,
        "loss": 0.9826605224609375
      },
      {
        "step": 800,
        "loss": 0.9215259552001953
      },
      {
        "step": 850,
        "loss": 0.9834632110595704
      },
      {
        "step": 900,
        "loss": 0.9540647888183593
      },
      {
        "step": 950,
        "loss": 0.8947990417480469
      },
      {
        "step": 1000,
        "loss": 0.8919943237304687
      },
      {
        "step": 1050,
        "loss": 0.944422607421875
      },
      {
        "step": 1100,
        "loss": 0.9449832916259766
      },
      {
        "step": 1150,
        "loss": 0.8802699279785157
      },
      {
        "step": 1200,
        "loss": 0.8814545440673828
      },
      {
        "step": 1250,
        "loss": 0.9049549865722656
      },
      {
        "step": 1300,
        "loss": 0.5215187454223633
      },
      {
        "step": 1350,
        "loss": 0.5252678298950195
      },
      {
        "step": 1400,
        "loss": 0.539795036315918
      },
      {
        "step": 1450,
        "loss": 0.543786506652832
      },
      {
        "step": 1500,
        "loss": 0.5319688415527344
      },
      {
        "step": 1550,
        "loss": 0.5629978561401368
      },
      {
        "step": 1600,
        "loss": 0.5546495819091797
      },
      {
        "step": 1650,
        "loss": 0.5151663589477539
      },
      {
        "step": 1700,
        "loss": 0.5445696640014649
      },
      {
        "step": 1750,
        "loss": 0.5218457412719727
      },
      {
        "step": 1800,
        "loss": 0.5212171936035156
      },
      {
        "step": 1850,
        "loss": 0.5296870040893554
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.158,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.086,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.112,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.09,
            "total": 500
          },
          "language": {
            "accuracy": 0.254,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.17,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.058,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.098,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.094,
            "total": 500
          },
          "language": {
            "accuracy": 0.248,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.132,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.004,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.106,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.23,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.106,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.03,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.108,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.082,
            "total": 500
          },
          "language": {
            "accuracy": 0.272,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.108,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.022,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.112,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.088,
            "total": 500
          },
          "language": {
            "accuracy": 0.202,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.124,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.02,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.102,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.234,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-0.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.11,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.04,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.106,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.258,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-1.5B_lr1e-05",
    "model": "Qwen/Qwen2.5-1.5B",
    "learning_rate": 1e-05,
    "training_losses": [
      {
        "step": 50,
        "loss": 1.1047867584228515
      },
      {
        "step": 100,
        "loss": 1.0084423828125
      },
      {
        "step": 150,
        "loss": 1.0033228302001953
      },
      {
        "step": 200,
        "loss": 1.0313528442382813
      },
      {
        "step": 250,
        "loss": 0.9879988098144531
      },
      {
        "step": 300,
        "loss": 0.9897730255126953
      },
      {
        "step": 350,
        "loss": 0.9525487518310547
      },
      {
        "step": 400,
        "loss": 0.9577235412597657
      },
      {
        "step": 450,
        "loss": 1.0037985992431642
      },
      {
        "step": 500,
        "loss": 1.0311649322509766
      },
      {
        "step": 550,
        "loss": 1.0327774810791015
      },
      {
        "step": 600,
        "loss": 0.9684050750732421
      },
      {
        "step": 650,
        "loss": 0.9936497497558594
      },
      {
        "step": 700,
        "loss": 0.9413753509521484
      },
      {
        "step": 750,
        "loss": 1.0034909820556641
      },
      {
        "step": 800,
        "loss": 0.9282119750976563
      },
      {
        "step": 850,
        "loss": 1.0057804107666015
      },
      {
        "step": 900,
        "loss": 1.0014503479003907
      },
      {
        "step": 950,
        "loss": 0.9377886199951172
      },
      {
        "step": 1000,
        "loss": 0.9518363952636719
      },
      {
        "step": 1050,
        "loss": 1.004217529296875
      },
      {
        "step": 1100,
        "loss": 0.9766322326660156
      },
      {
        "step": 1150,
        "loss": 0.9433235168457031
      },
      {
        "step": 1200,
        "loss": 0.9487670135498046
      },
      {
        "step": 1250,
        "loss": 0.9666649627685547
      },
      {
        "step": 1300,
        "loss": 0.9065851593017578
      },
      {
        "step": 1350,
        "loss": 0.9620731353759766
      },
      {
        "step": 1400,
        "loss": 0.9737167358398438
      },
      {
        "step": 1450,
        "loss": 0.9975327301025391
      },
      {
        "step": 1500,
        "loss": 0.9421812438964844
      },
      {
        "step": 1550,
        "loss": 0.9864193725585938
      },
      {
        "step": 1600,
        "loss": 0.9769078826904297
      },
      {
        "step": 1650,
        "loss": 0.9347907257080078
      },
      {
        "step": 1700,
        "loss": 0.9660159301757812
      },
      {
        "step": 1750,
        "loss": 0.9627749633789062
      },
      {
        "step": 1800,
        "loss": 0.9448778533935547
      },
      {
        "step": 1850,
        "loss": 0.939490966796875
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.274,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.07,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.268,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.288,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.06,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.126,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.256,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.288,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.086,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.122,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.256,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.298,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.098,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.12,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.258,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.292,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.094,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.12,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.076,
            "total": 500
          },
          "language": {
            "accuracy": 0.252,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.29,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.094,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.12,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.076,
            "total": 500
          },
          "language": {
            "accuracy": 0.254,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.294,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.082,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.122,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.252,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-1.5B_lr5e-05",
    "model": "Qwen/Qwen2.5-1.5B",
    "learning_rate": 5e-05,
    "training_losses": [
      {
        "step": 50,
        "loss": 1.0381784057617187
      },
      {
        "step": 100,
        "loss": 1.0207836151123046
      },
      {
        "step": 150,
        "loss": 1.0369874572753905
      },
      {
        "step": 200,
        "loss": 1.0733319091796876
      },
      {
        "step": 250,
        "loss": 1.035759506225586
      },
      {
        "step": 300,
        "loss": 1.0347379302978517
      },
      {
        "step": 350,
        "loss": 1.0009375
      },
      {
        "step": 400,
        "loss": 1.001897964477539
      },
      {
        "step": 450,
        "loss": 1.0537596893310548
      },
      {
        "step": 500,
        "loss": 1.078953857421875
      },
      {
        "step": 550,
        "loss": 1.0779857635498047
      },
      {
        "step": 600,
        "loss": 1.0119304656982422
      },
      {
        "step": 650,
        "loss": 0.9321826934814453
      },
      {
        "step": 700,
        "loss": 0.7600067138671875
      },
      {
        "step": 750,
        "loss": 0.8135604858398438
      },
      {
        "step": 800,
        "loss": 0.7471610260009766
      },
      {
        "step": 850,
        "loss": 0.8208379364013672
      },
      {
        "step": 900,
        "loss": 0.8105657196044922
      },
      {
        "step": 950,
        "loss": 0.752271728515625
      },
      {
        "step": 1000,
        "loss": 0.7654142761230469
      },
      {
        "step": 1050,
        "loss": 0.813240966796875
      },
      {
        "step": 1100,
        "loss": 0.7953347015380859
      },
      {
        "step": 1150,
        "loss": 0.7582463073730469
      },
      {
        "step": 1200,
        "loss": 0.765684585571289
      },
      {
        "step": 1250,
        "loss": 0.7807898712158203
      },
      {
        "step": 1300,
        "loss": 0.619776725769043
      },
      {
        "step": 1350,
        "loss": 0.6599774169921875
      },
      {
        "step": 1400,
        "loss": 0.6620439910888671
      },
      {
        "step": 1450,
        "loss": 0.6820939636230469
      },
      {
        "step": 1500,
        "loss": 0.6469348907470703
      },
      {
        "step": 1550,
        "loss": 0.6770085144042969
      },
      {
        "step": 1600,
        "loss": 0.6711241149902344
      },
      {
        "step": 1650,
        "loss": 0.635989112854004
      },
      {
        "step": 1700,
        "loss": 0.6583097076416016
      },
      {
        "step": 1750,
        "loss": 0.6454981231689453
      },
      {
        "step": 1800,
        "loss": 0.6364742660522461
      },
      {
        "step": 1850,
        "loss": 0.6441868591308594
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.274,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.07,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.268,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.268,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.068,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.118,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.08,
            "total": 500
          },
          "language": {
            "accuracy": 0.266,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.294,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.05,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.288,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.306,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.066,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.134,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.084,
            "total": 500
          },
          "language": {
            "accuracy": 0.284,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.268,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.048,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.124,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.286,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.264,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.044,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.126,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.082,
            "total": 500
          },
          "language": {
            "accuracy": 0.26,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.252,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.06,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.134,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.084,
            "total": 500
          },
          "language": {
            "accuracy": 0.256,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-1.5B_lr0.0001",
    "model": "Qwen/Qwen2.5-1.5B",
    "learning_rate": 0.0001,
    "training_losses": [
      {
        "step": 50,
        "loss": 1.0334608459472656
      },
      {
        "step": 100,
        "loss": 1.1398428344726563
      },
      {
        "step": 150,
        "loss": 1.2100322723388672
      },
      {
        "step": 200,
        "loss": 1.2477149200439452
      },
      {
        "step": 250,
        "loss": 1.227024917602539
      },
      {
        "step": 300,
        "loss": 1.2221176147460937
      },
      {
        "step": 350,
        "loss": 1.1919342041015626
      },
      {
        "step": 400,
        "loss": 1.1836582946777343
      },
      {
        "step": 450,
        "loss": 1.2420359802246095
      },
      {
        "step": 500,
        "loss": 1.2595484924316407
      },
      {
        "step": 550,
        "loss": 1.2528677368164063
      },
      {
        "step": 600,
        "loss": 1.1854230499267577
      },
      {
        "step": 650,
        "loss": 0.9783920288085938
      },
      {
        "step": 700,
        "loss": 0.6673809814453125
      },
      {
        "step": 750,
        "loss": 0.7058796691894531
      },
      {
        "step": 800,
        "loss": 0.6561112213134765
      },
      {
        "step": 850,
        "loss": 0.7165767669677734
      },
      {
        "step": 900,
        "loss": 0.6932662200927734
      },
      {
        "step": 950,
        "loss": 0.6419939422607421
      },
      {
        "step": 1000,
        "loss": 0.6437111663818359
      },
      {
        "step": 1050,
        "loss": 0.6806051635742187
      },
      {
        "step": 1100,
        "loss": 0.6813984680175781
      },
      {
        "step": 1150,
        "loss": 0.6340178298950195
      },
      {
        "step": 1200,
        "loss": 0.6408586120605468
      },
      {
        "step": 1250,
        "loss": 0.6475069427490234
      },
      {
        "step": 1300,
        "loss": 0.3595906448364258
      },
      {
        "step": 1350,
        "loss": 0.3626991653442383
      },
      {
        "step": 1400,
        "loss": 0.36479976654052737
      },
      {
        "step": 1450,
        "loss": 0.37182437896728515
      },
      {
        "step": 1500,
        "loss": 0.3609724807739258
      },
      {
        "step": 1550,
        "loss": 0.37832794189453123
      },
      {
        "step": 1600,
        "loss": 0.3730026626586914
      },
      {
        "step": 1650,
        "loss": 0.3487721633911133
      },
      {
        "step": 1700,
        "loss": 0.36258468627929685
      },
      {
        "step": 1750,
        "loss": 0.35637115478515624
      },
      {
        "step": 1800,
        "loss": 0.3603012466430664
      },
      {
        "step": 1850,
        "loss": 0.362493896484375
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.274,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.07,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.078,
            "total": 500
          },
          "language": {
            "accuracy": 0.268,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.306,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.048,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.118,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.088,
            "total": 500
          },
          "language": {
            "accuracy": 0.288,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.278,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.028,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.142,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.08,
            "total": 500
          },
          "language": {
            "accuracy": 0.29,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.23,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.058,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.136,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.084,
            "total": 500
          },
          "language": {
            "accuracy": 0.278,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.192,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.03,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.124,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.082,
            "total": 500
          },
          "language": {
            "accuracy": 0.284,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.19,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.018,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.084,
            "total": 500
          },
          "language": {
            "accuracy": 0.274,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-1.5B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.198,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.042,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.14,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.268,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-3B_lr1e-05",
    "model": "Qwen/Qwen2.5-3B",
    "learning_rate": 1e-05,
    "training_losses": [
      {
        "step": 50,
        "loss": 0.9812985992431641
      },
      {
        "step": 100,
        "loss": 0.9102021789550782
      },
      {
        "step": 150,
        "loss": 0.8944032287597656
      },
      {
        "step": 200,
        "loss": 0.9277171325683594
      },
      {
        "step": 250,
        "loss": 0.8868092346191406
      },
      {
        "step": 300,
        "loss": 0.8877154541015625
      },
      {
        "step": 350,
        "loss": 0.8527298736572265
      },
      {
        "step": 400,
        "loss": 0.8598078918457032
      },
      {
        "step": 450,
        "loss": 0.9047440338134766
      },
      {
        "step": 500,
        "loss": 0.9259491729736328
      },
      {
        "step": 550,
        "loss": 0.929409408569336
      },
      {
        "step": 600,
        "loss": 0.8785025787353515
      },
      {
        "step": 650,
        "loss": 0.8859507751464843
      },
      {
        "step": 700,
        "loss": 0.8314214324951172
      },
      {
        "step": 750,
        "loss": 0.8802349090576171
      },
      {
        "step": 800,
        "loss": 0.8149592590332031
      },
      {
        "step": 850,
        "loss": 0.8919887542724609
      },
      {
        "step": 900,
        "loss": 0.8952959442138672
      },
      {
        "step": 950,
        "loss": 0.829631576538086
      },
      {
        "step": 1000,
        "loss": 0.8501018524169922
      },
      {
        "step": 1050,
        "loss": 0.8943182373046875
      },
      {
        "step": 1100,
        "loss": 0.8688478088378906
      },
      {
        "step": 1150,
        "loss": 0.8361576843261719
      },
      {
        "step": 1200,
        "loss": 0.839078369140625
      },
      {
        "step": 1250,
        "loss": 0.8498224639892578
      },
      {
        "step": 1300,
        "loss": 0.8012782287597656
      },
      {
        "step": 1350,
        "loss": 0.8550033569335938
      },
      {
        "step": 1400,
        "loss": 0.8490518188476562
      },
      {
        "step": 1450,
        "loss": 0.8827146911621093
      },
      {
        "step": 1500,
        "loss": 0.829403305053711
      },
      {
        "step": 1550,
        "loss": 0.8731468963623047
      },
      {
        "step": 1600,
        "loss": 0.8603996276855469
      },
      {
        "step": 1650,
        "loss": 0.8182517242431641
      },
      {
        "step": 1700,
        "loss": 0.8528789520263672
      },
      {
        "step": 1750,
        "loss": 0.846093521118164
      },
      {
        "step": 1800,
        "loss": 0.8280400848388672
      },
      {
        "step": 1850,
        "loss": 0.8368700408935547
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.306,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.094,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.13,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.276,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.292,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.088,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.272,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.288,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.09,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.126,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.094,
            "total": 500
          },
          "language": {
            "accuracy": 0.272,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.288,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.094,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.126,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.09,
            "total": 500
          },
          "language": {
            "accuracy": 0.272,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.294,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.084,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.126,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.266,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.294,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.086,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.266,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 1e-05,
        "results": {
          "factual": {
            "accuracy": 0.298,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.088,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.126,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.094,
            "total": 500
          },
          "language": {
            "accuracy": 0.274,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-3B_lr5e-05",
    "model": "Qwen/Qwen2.5-3B",
    "learning_rate": 5e-05,
    "training_losses": [
      {
        "step": 50,
        "loss": 0.93498291015625
      },
      {
        "step": 100,
        "loss": 0.9288433837890625
      },
      {
        "step": 150,
        "loss": 0.9367903900146485
      },
      {
        "step": 200,
        "loss": 0.9826621246337891
      },
      {
        "step": 250,
        "loss": 0.9499786376953125
      },
      {
        "step": 300,
        "loss": 0.9439478302001953
      },
      {
        "step": 350,
        "loss": 0.9139930725097656
      },
      {
        "step": 400,
        "loss": 0.9176435089111328
      },
      {
        "step": 450,
        "loss": 0.9685490417480469
      },
      {
        "step": 500,
        "loss": 0.988430404663086
      },
      {
        "step": 550,
        "loss": 0.986280288696289
      },
      {
        "step": 600,
        "loss": 0.9344719696044922
      },
      {
        "step": 650,
        "loss": 0.829090347290039
      },
      {
        "step": 700,
        "loss": 0.6462550354003906
      },
      {
        "step": 750,
        "loss": 0.6940522003173828
      },
      {
        "step": 800,
        "loss": 0.628237648010254
      },
      {
        "step": 850,
        "loss": 0.7016218566894531
      },
      {
        "step": 900,
        "loss": 0.7001614379882812
      },
      {
        "step": 950,
        "loss": 0.6358698654174805
      },
      {
        "step": 1000,
        "loss": 0.6499581909179688
      },
      {
        "step": 1050,
        "loss": 0.6936693572998047
      },
      {
        "step": 1100,
        "loss": 0.6800991821289063
      },
      {
        "step": 1150,
        "loss": 0.6453618621826172
      },
      {
        "step": 1200,
        "loss": 0.6430745697021485
      },
      {
        "step": 1250,
        "loss": 0.6607527160644531
      },
      {
        "step": 1300,
        "loss": 0.48627773284912107
      },
      {
        "step": 1350,
        "loss": 0.5183242797851563
      },
      {
        "step": 1400,
        "loss": 0.5097630310058594
      },
      {
        "step": 1450,
        "loss": 0.5349506759643554
      },
      {
        "step": 1500,
        "loss": 0.5036082458496094
      },
      {
        "step": 1550,
        "loss": 0.5307653045654297
      },
      {
        "step": 1600,
        "loss": 0.5244358444213867
      },
      {
        "step": 1650,
        "loss": 0.48697715759277344
      },
      {
        "step": 1700,
        "loss": 0.5112482833862305
      },
      {
        "step": 1750,
        "loss": 0.4992795944213867
      },
      {
        "step": 1800,
        "loss": 0.4994573211669922
      },
      {
        "step": 1850,
        "loss": 0.5053247451782227
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.306,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.094,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.13,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.276,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.322,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.088,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.128,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.088,
            "total": 500
          },
          "language": {
            "accuracy": 0.268,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.348,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.074,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.136,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.088,
            "total": 500
          },
          "language": {
            "accuracy": 0.278,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.364,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.084,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.144,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.264,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.302,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.048,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.142,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.09,
            "total": 500
          },
          "language": {
            "accuracy": 0.264,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.3,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.078,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.146,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.268,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 5e-05,
        "results": {
          "factual": {
            "accuracy": 0.264,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.058,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.144,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.268,
            "total": 500
          }
        }
      }
    ]
  },
  {
    "experiment_id": "Qwen2.5-3B_lr0.0001",
    "model": "Qwen/Qwen2.5-3B",
    "learning_rate": 0.0001,
    "training_losses": [
      {
        "step": 50,
        "loss": 0.9341805267333985
      },
      {
        "step": 100,
        "loss": 1.0616262817382813
      },
      {
        "step": 150,
        "loss": 1.134489974975586
      },
      {
        "step": 200,
        "loss": 1.1812274169921875
      },
      {
        "step": 250,
        "loss": 1.1688538360595704
      },
      {
        "step": 300,
        "loss": 1.1602017211914062
      },
      {
        "step": 350,
        "loss": 1.1653759002685546
      },
      {
        "step": 400,
        "loss": 1.1403721618652343
      },
      {
        "step": 450,
        "loss": 1.1935437774658204
      },
      {
        "step": 500,
        "loss": 1.200616912841797
      },
      {
        "step": 550,
        "loss": 1.196425018310547
      },
      {
        "step": 600,
        "loss": 1.1338821411132813
      },
      {
        "step": 650,
        "loss": 0.9100135803222656
      },
      {
        "step": 700,
        "loss": 0.5895367431640625
      },
      {
        "step": 750,
        "loss": 0.6251787948608398
      },
      {
        "step": 800,
        "loss": 0.5881673049926758
      },
      {
        "step": 850,
        "loss": 0.6356719207763671
      },
      {
        "step": 900,
        "loss": 0.6175527572631836
      },
      {
        "step": 950,
        "loss": 0.5622229766845703
      },
      {
        "step": 1000,
        "loss": 0.5639517211914062
      },
      {
        "step": 1050,
        "loss": 0.6015246963500976
      },
      {
        "step": 1100,
        "loss": 0.5988225936889648
      },
      {
        "step": 1150,
        "loss": 0.5613031387329102
      },
      {
        "step": 1200,
        "loss": 0.5582445907592773
      },
      {
        "step": 1250,
        "loss": 0.5676681137084961
      },
      {
        "step": 1300,
        "loss": 0.2582596778869629
      },
      {
        "step": 1350,
        "loss": 0.2563591194152832
      },
      {
        "step": 1400,
        "loss": 0.2609731864929199
      },
      {
        "step": 1450,
        "loss": 0.26620298385620117
      },
      {
        "step": 1500,
        "loss": 0.2617019462585449
      },
      {
        "step": 1550,
        "loss": 0.2734229850769043
      },
      {
        "step": 1600,
        "loss": 0.26603883743286133
      },
      {
        "step": 1650,
        "loss": 0.24551286697387695
      },
      {
        "step": 1700,
        "loss": 0.2594025993347168
      },
      {
        "step": 1750,
        "loss": 0.250467529296875
      },
      {
        "step": 1800,
        "loss": 0.2529545211791992
      },
      {
        "step": 1850,
        "loss": 0.2609260177612305
      }
    ],
    "checkpoint_evaluations": [
      {
        "step": 0,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.306,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.094,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.13,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.276,
            "total": 500
          }
        }
      },
      {
        "step": 50,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.36,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.078,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.138,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.092,
            "total": 500
          },
          "language": {
            "accuracy": 0.276,
            "total": 500
          }
        }
      },
      {
        "step": 100,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.34,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.034,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.142,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.088,
            "total": 500
          },
          "language": {
            "accuracy": 0.288,
            "total": 500
          }
        }
      },
      {
        "step": 200,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.316,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.094,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.138,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.09,
            "total": 500
          },
          "language": {
            "accuracy": 0.286,
            "total": 500
          }
        }
      },
      {
        "step": 400,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.256,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.07,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.132,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.088,
            "total": 500
          },
          "language": {
            "accuracy": 0.266,
            "total": 500
          }
        }
      },
      {
        "step": 800,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.256,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.048,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.14,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.264,
            "total": 500
          }
        }
      },
      {
        "step": 1600,
        "model": "Qwen/Qwen2.5-3B",
        "lr": 0.0001,
        "results": {
          "factual": {
            "accuracy": 0.232,
            "total": 500
          },
          "reasoning": {
            "accuracy": 0.036,
            "total": 500
          },
          "commonsense": {
            "accuracy": 0.138,
            "total": 500
          },
          "knowledge": {
            "accuracy": 0.086,
            "total": 500
          },
          "language": {
            "accuracy": 0.264,
            "total": 500
          }
        }
      }
    ]
  }
]